{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "paper2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emadaghajanzadeh/sklearn_pycon2015/blob/master/paper2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DDQZqzFlpT",
        "colab_type": "text"
      },
      "source": [
        "<span style=\"color:purple;font-size:3em;\">**Mnist-convl-implement like paper**\n",
        "</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXWJpHCZFlpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Conv2D, MaxPooling2D, Flatten,BatchNormalization,Conv1D,MaxPooling1D,Dropout , Lambda\n",
        "from keras import initializers\n",
        "\n",
        "image_size = 28\n",
        "num_channels = 0\n",
        "num_features = image_size * image_size \n",
        "num_classes = 10\n",
        "\n",
        "num_train = 60000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVDYPy3-aeBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "d9e6b263-b260-4978-a5f2-e2a20dbced49"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os , pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def load_cifar10_batch(filename):\n",
        "  # \"load signle batch from CIFAR10\"\n",
        "    with open(filename , 'rb') as f  : \n",
        "     datadict = pickle.load(f , encoding='bytes')\n",
        "     X = datadict[b'data']\n",
        "     Y = datadict[b'labels']\n",
        "     X = X.reshape(10000 , 3 , 32 , 32)\n",
        "     X = X.transpose(0 , 2 , 3 , 1).astype('float')\n",
        "     Y = np.array(Y)\n",
        "     return X , Y\n",
        "\n",
        "def load_cifar10(dir):\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for i in range(1 , 6):\n",
        "    filenamev = os.path.join(dir , 'data_batch_%d' %i)\n",
        "    X , Y = load_cifar10_batch(filenamev)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)\n",
        "\n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X , Y\n",
        "\n",
        "  Xte , Yte  = load_cifar10_batch(os.path.join(dir , 'test_batch'))\n",
        "  return Xtr , Ytr , Xte , Yte\n",
        "\n",
        "X_train , y_train , X_test , y_test = load_cifar10('./drive/My Drive/Colab Notebooks/datasets/cifar-10-batches-py')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ71GCyoFlpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "87eb76fa-ae76-469b-c1db-9d926574fbfc"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test)\n",
        "print('Train data shape: {}'.format(X_train.shape))\n",
        "print('Test  data shape: {}'.format(X_test.shape))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data shape: (50000, 32, 32, 3)\n",
            "Test  data shape: (10000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5xJmphvFlpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "07edc9b5-d1ce-4873-bb62-4baf7384c4ab"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#########   !!!\n",
        "# print((num_features,))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXucWhTFlpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_cnn(model_name):\n",
        "    model = Sequential()\n",
        "    if(model_name==\"without_dropout\"):\n",
        "        #######################################  without_dropout  ##################   \n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(6, kernel_size=(5 , 5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros())) \n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(12,kernel_size=(5 ,5 ), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2 , 2),strides=2))\n",
        "        # Classifier\n",
        "        model.add(Flatten())                                                         \n",
        "        model.add(Dense(1000, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "        \n",
        "####################################################### max_pooling##################   \n",
        "   \n",
        "    elif(model_name==\"max_pooling\"):\n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(6, kernel_size=(5 , 5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros())) \n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "       \n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(12,kernel_size=(5,5), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        \n",
        "        # Classifier\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1000, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    elif(model_name==\"scaled_max_pooling\"):\n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(6, kernel_size=(5,5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros())) \n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        model.add(Lambda(lambda x: x * 0.5))\n",
        "       \n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(12,kernel_size=(5,5), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "        model.add(Lambda(lambda x: x * 0.5))\n",
        "        \n",
        "        # Classifier\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1000, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "#print model\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNKjHkUfFlp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "551f0f45-a2ce-4812-ea34-69eab442bba7"
      },
      "source": [
        "model = create_cnn(\"without_dropout\")\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "\n",
        "# boundaries = [20000, 40000]\n",
        "# values = [0.1, 0.01, 0.001]\n",
        "# learning_rate_fn= tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "#     boundaries, values)\n",
        "\n",
        "# # Later, whenever we perform an optimization step, we pass in the step.\n",
        "# learning_rate = learning_rate_fn(step)\n",
        "optimizer = keras.optimizers.SGD(learning_rate = 0.001 , momentum=0.95)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_without_dropout=model.fit(X_train[:50000 ], y_train[:50000 , :],\n",
        "#           batch_size=100,\n",
        "#           epochs=15\n",
        "#           ,validation_data=(X_train[50000: , :], X_train[50000: , :]))\n",
        "\n",
        "history_without_dropout = model.fit(X_train , y_train , batch_size = 100 , epochs = 55 , validation_split=1/6)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "          \n",
        "          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-821c60edfb3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#           ,validation_data=(X_train[50000: , :], X_train[50000: , :]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mhistory_without_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m55\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC1qZfzfFlp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15e66ba1-48be-4f40-d0d4-f0a320d5869f"
      },
      "source": [
        "model = create_cnn(\"max_pooling\")\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "\n",
        "# boundaries = [20000, 40000]\n",
        "# values = [0.1, 0.01, 0.001]\n",
        "# learning_rate_fn= tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "#     boundaries, values)\n",
        "\n",
        "# # Later, whenever we perform an optimization step, we pass in the step.\n",
        "# learning_rate = learning_rate_fn(step)\n",
        "optimizer = keras.optimizers.SGD(learning_rate = 0.001 , momentum=0.95)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_without_dropout=model.fit(X_train[:50000 ], y_train[:50000 , :],\n",
        "#           batch_size=100,\n",
        "#           epochs=15\n",
        "#           ,validation_data=(X_train[50000: , :], X_train[50000: , :]))\n",
        "\n",
        "history_max_pooling = model.fit(X_train , y_train , batch_size = 100 , epochs = 55 , validation_split=1/6)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 1.8347 - accuracy: 0.3298 - val_loss: 1.8507 - val_accuracy: 0.3925\n",
            "Epoch 2/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.5416 - accuracy: 0.4463 - val_loss: 1.7663 - val_accuracy: 0.4114\n",
            "Epoch 3/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.4529 - accuracy: 0.4778 - val_loss: 1.7292 - val_accuracy: 0.3962\n",
            "Epoch 4/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.3909 - accuracy: 0.5027 - val_loss: 1.7618 - val_accuracy: 0.3884\n",
            "Epoch 5/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.3361 - accuracy: 0.5261 - val_loss: 1.6978 - val_accuracy: 0.3987\n",
            "Epoch 6/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.2895 - accuracy: 0.5408 - val_loss: 1.6167 - val_accuracy: 0.4422\n",
            "Epoch 7/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.2514 - accuracy: 0.5561 - val_loss: 1.6728 - val_accuracy: 0.4050\n",
            "Epoch 8/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.2112 - accuracy: 0.5724 - val_loss: 1.7130 - val_accuracy: 0.3892\n",
            "Epoch 9/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.1756 - accuracy: 0.5847 - val_loss: 1.6089 - val_accuracy: 0.4358\n",
            "Epoch 10/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.1332 - accuracy: 0.5984 - val_loss: 1.6529 - val_accuracy: 0.4243\n",
            "Epoch 11/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.1003 - accuracy: 0.6125 - val_loss: 1.6000 - val_accuracy: 0.4456\n",
            "Epoch 12/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.0672 - accuracy: 0.6228 - val_loss: 1.5762 - val_accuracy: 0.4450\n",
            "Epoch 13/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.0384 - accuracy: 0.6310 - val_loss: 1.5462 - val_accuracy: 0.4672\n",
            "Epoch 14/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 1.0036 - accuracy: 0.6433 - val_loss: 1.5180 - val_accuracy: 0.4836\n",
            "Epoch 15/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.9812 - accuracy: 0.6527 - val_loss: 1.5502 - val_accuracy: 0.4587\n",
            "Epoch 16/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.9499 - accuracy: 0.6630 - val_loss: 1.5786 - val_accuracy: 0.4461\n",
            "Epoch 17/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.9264 - accuracy: 0.6709 - val_loss: 1.5116 - val_accuracy: 0.4714\n",
            "Epoch 18/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.9026 - accuracy: 0.6790 - val_loss: 1.5295 - val_accuracy: 0.4653\n",
            "Epoch 19/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.8837 - accuracy: 0.6847 - val_loss: 1.6923 - val_accuracy: 0.4182\n",
            "Epoch 20/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.8568 - accuracy: 0.6927 - val_loss: 1.4621 - val_accuracy: 0.4944\n",
            "Epoch 21/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.8385 - accuracy: 0.7043 - val_loss: 1.6408 - val_accuracy: 0.4386\n",
            "Epoch 22/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.8214 - accuracy: 0.7054 - val_loss: 1.5307 - val_accuracy: 0.4674\n",
            "Epoch 23/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7977 - accuracy: 0.7171 - val_loss: 1.5877 - val_accuracy: 0.4556\n",
            "Epoch 24/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7864 - accuracy: 0.7223 - val_loss: 1.5584 - val_accuracy: 0.4653\n",
            "Epoch 25/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7623 - accuracy: 0.7294 - val_loss: 1.5647 - val_accuracy: 0.4567\n",
            "Epoch 26/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7566 - accuracy: 0.7304 - val_loss: 1.5893 - val_accuracy: 0.4483\n",
            "Epoch 27/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.7393 - accuracy: 0.7381 - val_loss: 1.5278 - val_accuracy: 0.4646\n",
            "Epoch 28/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7264 - accuracy: 0.7410 - val_loss: 1.4911 - val_accuracy: 0.4808\n",
            "Epoch 29/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.7122 - accuracy: 0.7461 - val_loss: 1.5688 - val_accuracy: 0.4568\n",
            "Epoch 30/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6961 - accuracy: 0.7523 - val_loss: 1.4909 - val_accuracy: 0.4773\n",
            "Epoch 31/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.7518 - val_loss: 1.5997 - val_accuracy: 0.4466\n",
            "Epoch 32/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6795 - accuracy: 0.7587 - val_loss: 1.6252 - val_accuracy: 0.4422\n",
            "Epoch 33/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6677 - accuracy: 0.7621 - val_loss: 1.5591 - val_accuracy: 0.4636\n",
            "Epoch 34/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.7644 - val_loss: 1.5929 - val_accuracy: 0.4504\n",
            "Epoch 35/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6599 - accuracy: 0.7630 - val_loss: 1.5607 - val_accuracy: 0.4592\n",
            "Epoch 36/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6410 - accuracy: 0.7722 - val_loss: 1.5568 - val_accuracy: 0.4632\n",
            "Epoch 37/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6297 - accuracy: 0.7743 - val_loss: 1.5682 - val_accuracy: 0.4594\n",
            "Epoch 38/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.6300 - accuracy: 0.7761 - val_loss: 1.5937 - val_accuracy: 0.4605\n",
            "Epoch 39/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6132 - accuracy: 0.7854 - val_loss: 1.6025 - val_accuracy: 0.4515\n",
            "Epoch 40/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6101 - accuracy: 0.7823 - val_loss: 1.5675 - val_accuracy: 0.4638\n",
            "Epoch 41/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.7851 - val_loss: 1.5047 - val_accuracy: 0.4791\n",
            "Epoch 42/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5922 - accuracy: 0.7888 - val_loss: 1.5358 - val_accuracy: 0.4832\n",
            "Epoch 43/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5900 - accuracy: 0.7922 - val_loss: 1.5795 - val_accuracy: 0.4714\n",
            "Epoch 44/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5786 - accuracy: 0.7953 - val_loss: 1.5241 - val_accuracy: 0.4766\n",
            "Epoch 45/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5781 - accuracy: 0.7929 - val_loss: 1.6879 - val_accuracy: 0.4396\n",
            "Epoch 46/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5636 - accuracy: 0.7973 - val_loss: 1.5984 - val_accuracy: 0.4562\n",
            "Epoch 47/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5688 - accuracy: 0.7974 - val_loss: 1.6161 - val_accuracy: 0.4537\n",
            "Epoch 48/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.5607 - accuracy: 0.8004 - val_loss: 1.5678 - val_accuracy: 0.4708\n",
            "Epoch 49/55\n",
            "417/417 [==============================] - 2s 5ms/step - loss: 0.5581 - accuracy: 0.8031 - val_loss: 1.4895 - val_accuracy: 0.4916\n",
            "Epoch 50/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5575 - accuracy: 0.8002 - val_loss: 1.5759 - val_accuracy: 0.4620\n",
            "Epoch 51/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5424 - accuracy: 0.8080 - val_loss: 1.6597 - val_accuracy: 0.4472\n",
            "Epoch 52/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5433 - accuracy: 0.8060 - val_loss: 1.5968 - val_accuracy: 0.4542\n",
            "Epoch 53/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5346 - accuracy: 0.8107 - val_loss: 1.5838 - val_accuracy: 0.4693\n",
            "Epoch 54/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5342 - accuracy: 0.8127 - val_loss: 1.6137 - val_accuracy: 0.4527\n",
            "Epoch 55/55\n",
            "417/417 [==============================] - 2s 4ms/step - loss: 0.5244 - accuracy: 0.8139 - val_loss: 1.6530 - val_accuracy: 0.4503\n",
            "Test loss: 1.646574854850769\n",
            "Test accuracy: 0.45170000195503235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4TDDcZ-eM4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3cccd4a-a2c3-4f62-9cc0-e6dc3dfa9db7"
      },
      "source": [
        "model = create_cnn(\"scaled_max_pooling\")\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "# step = tf.Variable(0, trainable=False)\n",
        "\n",
        "# boundaries = [20000, 40000]\n",
        "# values = [0.1, 0.01, 0.001]\n",
        "# learning_rate_fn= tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "#     boundaries, values)\n",
        "\n",
        "# # Later, whenever we perform an optimization step, we pass in the step.\n",
        "# learning_rate = learning_rate_fn(step)\n",
        "optimizer = keras.optimizers.SGD(learning_rate = 0.001 , momentum=0.95)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# history_without_dropout=model.fit(X_train[:50000 ], y_train[:50000 , :],\n",
        "#           batch_size=100,\n",
        "#           epochs=15\n",
        "#           ,validation_data=(X_train[50000: , :], X_train[50000: , :]))\n",
        "\n",
        "history_scaled_max_pooling = model.fit(X_train , y_train , batch_size = 100 , epochs = 55 , validation_split=1/6)\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "417/417 [==============================] - 5s 11ms/step - loss: 1.8058 - accuracy: 0.3394 - val_loss: 1.9754 - val_accuracy: 0.2642\n",
            "Epoch 2/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.5899 - accuracy: 0.4220 - val_loss: 1.9684 - val_accuracy: 0.2846\n",
            "Epoch 3/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.5132 - accuracy: 0.4514 - val_loss: 1.9234 - val_accuracy: 0.2802\n",
            "Epoch 4/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.4555 - accuracy: 0.4756 - val_loss: 1.9123 - val_accuracy: 0.2819\n",
            "Epoch 5/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.4103 - accuracy: 0.4918 - val_loss: 2.0906 - val_accuracy: 0.2307\n",
            "Epoch 6/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.3647 - accuracy: 0.5075 - val_loss: 2.0084 - val_accuracy: 0.2647\n",
            "Epoch 7/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.3284 - accuracy: 0.5252 - val_loss: 1.8406 - val_accuracy: 0.3164\n",
            "Epoch 8/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.2899 - accuracy: 0.5391 - val_loss: 1.9913 - val_accuracy: 0.2694\n",
            "Epoch 9/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.2515 - accuracy: 0.5540 - val_loss: 1.9008 - val_accuracy: 0.3077\n",
            "Epoch 10/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.2163 - accuracy: 0.5676 - val_loss: 1.9631 - val_accuracy: 0.3045\n",
            "Epoch 11/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.1829 - accuracy: 0.5796 - val_loss: 1.9212 - val_accuracy: 0.3035\n",
            "Epoch 12/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.1475 - accuracy: 0.5924 - val_loss: 2.0318 - val_accuracy: 0.2919\n",
            "Epoch 13/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.1207 - accuracy: 0.6021 - val_loss: 1.9883 - val_accuracy: 0.2993\n",
            "Epoch 14/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.0893 - accuracy: 0.6126 - val_loss: 2.0699 - val_accuracy: 0.2783\n",
            "Epoch 15/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.0602 - accuracy: 0.6224 - val_loss: 2.1667 - val_accuracy: 0.2706\n",
            "Epoch 16/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.0321 - accuracy: 0.6343 - val_loss: 2.0148 - val_accuracy: 0.3061\n",
            "Epoch 17/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 1.0066 - accuracy: 0.6406 - val_loss: 1.9972 - val_accuracy: 0.3277\n",
            "Epoch 18/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.9867 - accuracy: 0.6496 - val_loss: 2.1783 - val_accuracy: 0.2849\n",
            "Epoch 19/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.9599 - accuracy: 0.6579 - val_loss: 2.0396 - val_accuracy: 0.3026\n",
            "Epoch 20/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.9388 - accuracy: 0.6633 - val_loss: 2.0360 - val_accuracy: 0.3239\n",
            "Epoch 21/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.9171 - accuracy: 0.6735 - val_loss: 1.9360 - val_accuracy: 0.3434\n",
            "Epoch 22/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.8969 - accuracy: 0.6807 - val_loss: 2.0175 - val_accuracy: 0.3301\n",
            "Epoch 23/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.8800 - accuracy: 0.6873 - val_loss: 2.1038 - val_accuracy: 0.3158\n",
            "Epoch 24/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.8589 - accuracy: 0.6930 - val_loss: 2.1864 - val_accuracy: 0.3083\n",
            "Epoch 25/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.8454 - accuracy: 0.6955 - val_loss: 2.0897 - val_accuracy: 0.3183\n",
            "Epoch 26/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.8250 - accuracy: 0.7039 - val_loss: 2.1489 - val_accuracy: 0.3060\n",
            "Epoch 27/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.8102 - accuracy: 0.7085 - val_loss: 2.1264 - val_accuracy: 0.3227\n",
            "Epoch 28/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7904 - accuracy: 0.7164 - val_loss: 2.1400 - val_accuracy: 0.3139\n",
            "Epoch 29/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7711 - accuracy: 0.7244 - val_loss: 1.9654 - val_accuracy: 0.3482\n",
            "Epoch 30/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7629 - accuracy: 0.7278 - val_loss: 2.1166 - val_accuracy: 0.3317\n",
            "Epoch 31/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7453 - accuracy: 0.7328 - val_loss: 2.0217 - val_accuracy: 0.3421\n",
            "Epoch 32/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7393 - accuracy: 0.7343 - val_loss: 1.9880 - val_accuracy: 0.3584\n",
            "Epoch 33/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7278 - accuracy: 0.7410 - val_loss: 2.0980 - val_accuracy: 0.3329\n",
            "Epoch 34/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.7177 - accuracy: 0.7417 - val_loss: 2.1051 - val_accuracy: 0.3379\n",
            "Epoch 35/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6985 - accuracy: 0.7493 - val_loss: 2.1412 - val_accuracy: 0.3378\n",
            "Epoch 36/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6981 - accuracy: 0.7483 - val_loss: 2.0946 - val_accuracy: 0.3404\n",
            "Epoch 37/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6769 - accuracy: 0.7587 - val_loss: 2.1237 - val_accuracy: 0.3399\n",
            "Epoch 38/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6714 - accuracy: 0.7581 - val_loss: 2.0577 - val_accuracy: 0.3498\n",
            "Epoch 39/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6637 - accuracy: 0.7618 - val_loss: 2.0009 - val_accuracy: 0.3619\n",
            "Epoch 40/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6494 - accuracy: 0.7660 - val_loss: 2.1160 - val_accuracy: 0.3415\n",
            "Epoch 41/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6457 - accuracy: 0.7683 - val_loss: 2.1511 - val_accuracy: 0.3303\n",
            "Epoch 42/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6377 - accuracy: 0.7703 - val_loss: 2.0622 - val_accuracy: 0.3547\n",
            "Epoch 43/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6207 - accuracy: 0.7761 - val_loss: 2.0620 - val_accuracy: 0.3551\n",
            "Epoch 44/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6204 - accuracy: 0.7769 - val_loss: 2.3974 - val_accuracy: 0.3103\n",
            "Epoch 45/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6100 - accuracy: 0.7809 - val_loss: 2.2339 - val_accuracy: 0.3333\n",
            "Epoch 46/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.5971 - accuracy: 0.7842 - val_loss: 2.2713 - val_accuracy: 0.3335\n",
            "Epoch 47/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.6024 - accuracy: 0.7826 - val_loss: 2.2320 - val_accuracy: 0.3312\n",
            "Epoch 48/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5849 - accuracy: 0.7897 - val_loss: 2.2853 - val_accuracy: 0.3243\n",
            "Epoch 49/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5880 - accuracy: 0.7899 - val_loss: 2.2002 - val_accuracy: 0.3404\n",
            "Epoch 50/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5745 - accuracy: 0.7932 - val_loss: 2.2909 - val_accuracy: 0.3434\n",
            "Epoch 51/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5749 - accuracy: 0.7929 - val_loss: 2.1439 - val_accuracy: 0.3511\n",
            "Epoch 52/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5617 - accuracy: 0.7998 - val_loss: 2.0347 - val_accuracy: 0.3715\n",
            "Epoch 53/55\n",
            "417/417 [==============================] - 4s 10ms/step - loss: 0.5606 - accuracy: 0.7983 - val_loss: 2.2044 - val_accuracy: 0.3445\n",
            "Epoch 54/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.5506 - accuracy: 0.8019 - val_loss: 2.2575 - val_accuracy: 0.3350\n",
            "Epoch 55/55\n",
            "417/417 [==============================] - 4s 9ms/step - loss: 0.5571 - accuracy: 0.7993 - val_loss: 2.2037 - val_accuracy: 0.3458\n",
            "Test loss: 2.183706283569336\n",
            "Test accuracy: 0.34929999709129333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5stLSmuYFlp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "3b0cc440-876c-44b7-ca2d-2bfd651317f4"
      },
      "source": [
        "\n",
        "plt.plot(history_without_dropout.history['loss'])\n",
        "# plt.plot(history_without_dropout.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train_without_loss'])\n",
        "plt.plot(history_scaled_max_pooling.history['loss'])\n",
        "plt.plot(history_max_pooling.history['loss'])\n",
        "# plt.plot(history_max_pooling.history['val_loss'])\n",
        "plt.legend(['train_without_dropout' , 'train_scaled_max_pooling' , 'train_max_pooling'])\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(history_without_dropout.history['loss'])\n",
        "plt.plot(history_without_dropout.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['val_without_loss'])\n",
        "\n",
        "# plt.plot(history_max_pooling.history['loss'])\n",
        "plt.plot(history_scaled_max_pooling.history['val_loss'])\n",
        "plt.plot(history_max_pooling.history['val_loss'])\n",
        "plt.legend(['val_without_dropout' ,\"val_scaled_max_pooling\", 'val_max_pooling'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history_without_dropout.history['loss'])\n",
        "plt.plot(history_without_dropout.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title(\"without drop out\")\n",
        "plt.legend(['train_loss' , 'validation_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_max_pooling.history['loss'])\n",
        "plt.plot(history_max_pooling.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title(\"max pooling\")\n",
        "plt.legend(['train_loss' , 'validation_loss'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e3408fd4162f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_without_dropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.plot(history_without_dropout.history['val_loss'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history_without_dropout' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz6cnqTwFlqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f0Yuw2JFlqH",
        "colab_type": "text"
      },
      "source": [
        "<span style=\"color:purple;font-size:3em;\">**Cfar10-convl-implement like paper**\n",
        "</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4yDOYJ3FlqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import initializers\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Dense,Activation,Conv2D, MaxPooling2D, Flatten,BatchNormalization,Dropout\n",
        "image_size = 32\n",
        "num_channels = 3\n",
        "num_features = image_size * image_size * num_channels\n",
        "num_classes = 10\n",
        "\n",
        "num_train = 49000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkG0vv0CFlqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "e97a7f00-14bc-4427-eca5-cec6d6b7e3b1"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('Train data shape: {}'.format(X_train.shape))\n",
        "print('Test  data shape: {}'.format(X_test.shape))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "Train data shape: (50000, 32, 32, 3)\n",
            "Test  data shape: (10000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLamIUWSFlqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "05c5b17e-0564-4983-fd8c-ebe486b8cb61"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "#########   !!!\n",
        "print((num_features,))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n",
            "(3072,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOXJxoNcmctP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K \n",
        "from keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "import time\n",
        "class OptimizedDroupout(Layer): \n",
        "   def __init__(self, keep_prob, **kwargs): \n",
        "      self.keep_prob = keep_prob\n",
        "      super(OptimizedDroupout, self).__init__(**kwargs) \n",
        "\n",
        "   def build(self, input_shape): \n",
        "      super(OptimizedDroupout, self).build(input_shape) # Be sure to call this at the end \n",
        "\n",
        "   def call(self, input_data): \n",
        "      mean =  tf.reduce_mean(input_data, axis=-1, keepdims=True)\n",
        "      tf.print(input_data)\n",
        "      tf.print(mean)\n",
        "      # time.sleep(30)\n",
        "      # with tf.Session() as sess:  print(mean.eval())       # print(\"emad\")\n",
        "      return input_data\n",
        "      # return K.dot(input_data, self.kernel) \n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "farR_iWVFlqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_cnn2(model_name):\n",
        "    model = Sequential()\n",
        "    if(model_name==\"without_dropout\"):\n",
        "        #######################################  without_dropout  ##################   \n",
        "            \n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(96, kernel_size=(5,5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros()))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(128,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "        # Conv Block 3\n",
        "        model.add(Conv2D(256,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "        # Classifier\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "        \n",
        "       ####################################################### max_pooling##################   \n",
        "   \n",
        "    elif(model_name==\"max_pooling\"):\n",
        "                              \n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(96, kernel_size=(5,5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros()))\n",
        "        model.add(Dropout(0.7))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(128,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "        \n",
        "        # Conv Block 3\n",
        "        model.add(Conv2D(256,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "       \n",
        "        # Classifier\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "         ####################################################### max_pooling##################   \n",
        "\n",
        "    elif(model_name==\"optimized_dropout\"):\n",
        "\n",
        "        # Conv Block 1 \n",
        "        model.add(Conv2D(96, kernel_size=(5,5), padding='same', input_shape=X_train.shape[1:], activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer=initializers.Zeros()))\n",
        "        model.add(Dropout(0.7))\n",
        "        model.add(OptimizedDroupout(0.7))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "\n",
        "        # Conv Block 2\n",
        "        model.add(Conv2D(128,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "        \n",
        "        # Conv Block 3\n",
        "        model.add(Conv2D(256,kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(MaxPooling2D(pool_size=(3,3),strides=2))\n",
        "       \n",
        "        # Classifier\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(2000, activation='relu'))\n",
        "        model.add(Dense(num_classes, activation='softmax'))\n",
        "        \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "#print model\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GnI8nfsFlqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_cnn2(\"optimized_dropout\")\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "'''step = tf.Variable(0, trainable=False)\n",
        "\n",
        "boundaries = [20000, 40000]\n",
        "values = [0.1, 0.01, 0.001]\n",
        "learning_rate_fn= tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries, values)\n",
        "'''\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01 , momentum = 0.95)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_max_pooling=model.fit(X_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=5\n",
        "          ,validation_data=(X_test, y_test))\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmYmLTvrFlqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "db117d37-4937-4791-9027-c640a1c87218"
      },
      "source": [
        "model = create_cnn2(\"max_pooling\")\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.001,momentum=0.95)\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01 , momentum = 0.95)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_max_pooling=model.fit(X_train, y_train,\n",
        "          batch_size=100,\n",
        "          epochs=5\n",
        "          ,validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  1/500 [..............................] - ETA: 9s - loss: 2.3024 - accuracy: 0.1300WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_train_batch_end` time: 0.0176s). Check your callbacks.\n",
            "500/500 [==============================] - 9s 17ms/step - loss: 1.8022 - accuracy: 0.3376 - val_loss: 2.2430 - val_accuracy: 0.1890\n",
            "Epoch 2/5\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.4592 - accuracy: 0.4738 - val_loss: 2.1977 - val_accuracy: 0.1748\n",
            "Epoch 3/5\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.3234 - accuracy: 0.5248 - val_loss: 2.1771 - val_accuracy: 0.2538\n",
            "Epoch 4/5\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.2320 - accuracy: 0.5632 - val_loss: 2.1649 - val_accuracy: 0.2400\n",
            "Epoch 5/5\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 1.1509 - accuracy: 0.5909 - val_loss: 2.0054 - val_accuracy: 0.3119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUQ9ReeFlqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "606e0155-fe2a-4dbd-a8c4-e399992ad79a"
      },
      "source": [
        "\n",
        "plt.plot(history_optimized_dropout.history['loss'])\n",
        "# plt.plot(history_without_dropout.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['train_without_loss'])\n",
        "\n",
        "plt.plot(history_max_pooling.history['loss'])\n",
        "# plt.plot(history_max_pooling.history['val_loss'])\n",
        "plt.legend(['train_without_dropout' , 'train_max_pooling'])\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(history_without_dropout.history['loss'])\n",
        "plt.plot(history_optimized_dropout.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.legend(['val_without_loss'])\n",
        "\n",
        "# plt.plot(history_max_pooling.history['loss'])\n",
        "plt.plot(history_max_pooling.history['val_loss'])\n",
        "plt.legend(['val_without_dropout' , 'val_max_pooling'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcad013c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2NHtqwBFlqy",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fff1745-efcc-4a64-cf03-8c69f4976bc1"
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 73us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3026821196079252, 0.10000000149011612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8nyRkzLFlq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}